

# ğŸ“Œ Structured Answer Generator

A production-style structured response generator built using **LiteLLM**, **Groq API**, and **Prompt Engineering**.

---

## ğŸ“– Overview

This project generates structured and deterministic JSON responses from a Large Language Model (LLM).

It ensures:

* Controlled output format
* Stable and predictable responses
* Separation of system and user prompts
* Production-ready architecture

---

## ğŸš€ Features

* âœ… Controlled JSON output format
* âœ… Deterministic prompting (temperature control)
* âœ… Production-style prompt separation
* âœ… Environment variable configuration
* âœ… Modular and clean code structure

---

## ğŸ›  Tech Stack

* Python
* LiteLLM
* Groq API
* python-dotenv

---

## ğŸ“‚ Project Structure

```
structured-answer-generator/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ prompts.py
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone <your-repo-url>
cd structured-answer-generator
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ” Environment Setup

Create a `.env` file in the root directory:

```
GROQ_API_KEY=your_api_key_here

```

Make sure your API key is valid and active.

---

## â–¶ï¸ Run the Application

```bash
python main.py
```

You will be prompted to enter:

* Your question
* Temperature value (0â€“1)

The system will return a structured JSON response.

---

## ğŸ“„ Output Format

The model strictly returns:

```json
{
  "title": "",
  "definition": "",
  "key_points": [],
  "example": "",
  "summary": ""
}
```

---

## ğŸ¯ Purpose of the Project

This project demonstrates:

* LLM orchestration
* API integration
* Prompt engineering
* Deterministic AI output control
* Production-ready AI system design

---
